{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel, get_peft_model\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURATION - REFINED FOR TRAIT ALIGNMENT\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Hugging Face & Cache Setup ---\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "HF_CACHE_DIR = \"/cs/student/projects3/aisd/2024/ghanda/cache\"\n",
    "os.environ[\"HF_HOME\"] = HF_CACHE_DIR\n",
    "\n",
    "# --- Model & Training Paths ---\n",
    "MODEL_NAME = \"google/gemma-2-2b\"\n",
    "OUTPUT_DIR_BASE = \"peft_output_models_v2_refined\"\n",
    "\n",
    "# --- QLoRA Parameters (Refined) ---\n",
    "lora_r = 128\n",
    "lora_alpha = 256\n",
    "lora_dropout = 0.05\n",
    "target_modules = [\n",
    "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "    \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "]\n",
    "\n",
    "# --- Quantization Parameters ---\n",
    "use_4bit = True\n",
    "bnb_4bit_compute_dtype = \"bfloat16\"\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "use_nested_quant = False\n",
    "\n",
    "# --- Training Parameters (Refined for Stability and Performance) ---\n",
    "num_train_epochs = 3\n",
    "fp16 = False\n",
    "bf16 = True\n",
    "per_device_train_batch_size = 2\n",
    "gradient_accumulation_steps = 4\n",
    "gradient_checkpointing = True\n",
    "max_grad_norm = 0.3\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0.01\n",
    "optim = \"paged_adamw_8bit\"\n",
    "lr_scheduler_type = \"cosine\"\n",
    "max_steps = -1\n",
    "warmup_ratio = 0.03\n",
    "group_by_length = True\n",
    "max_seq_length = 768\n",
    "packing = False # Important for SFTTrainer with our prompt format\n",
    "logging_steps = 25 # Log progress every 25 steps\n",
    "save_steps = 0 # Save only at the end of training\n",
    "\n",
    "# --- Device Mapping ---\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "# --- Dataset Names ---\n",
    "PERSONALITY_DATASET_NAME = \"holistic-ai/personality_manipulation\"\n",
    "OPINIONQA_DATASET_NAME = \"RiverDong/OpinionQA\"\n",
    "\n",
    "# ==============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def enhanced_training_prompt_format(sample):\n",
    "    \"\"\"\n",
    "    Enhanced prompt that explicitly defines the target personality for the model\n",
    "    during training, making the learning task unambiguous and far more effective.\n",
    "    \"\"\"\n",
    "    personality = sample['Target Personality']\n",
    "    question = sample['Question']\n",
    "    answer = sample['Answer']\n",
    "\n",
    "    if personality.lower() == 'extraversion':\n",
    "        personality_instruction = \"You are an AI assistant with a strong Extraversion personality. You are outgoing, energetic, and sociable. You love interacting with others and sharing your thoughts enthusiastically.\"\n",
    "    elif personality.lower() == 'agreeableness':\n",
    "        personality_instruction = \"You are an AI assistant with a strong Agreeableness personality. You are cooperative, trusting, and helpful. You prioritize harmony and others' well-being.\"\n",
    "    elif personality.lower() == 'conscientiousness':\n",
    "        personality_instruction = \"You are an AI assistant with a strong Conscientiousness personality. You are organized, responsible, and goal-oriented. You focus on accuracy and completing tasks properly.\"\n",
    "    elif personality.lower() == 'neuroticism':\n",
    "        personality_instruction = \"You are an AI assistant with a strong Neuroticism personality. You tend to experience negative emotions more intensely and may express worry or anxiety.\"\n",
    "    elif personality.lower() == 'openness':\n",
    "        personality_instruction = \"You are an AI assistant with a strong Openness personality. You are curious, creative, and open to new experiences. You enjoy exploring ideas and possibilities.\"\n",
    "    else:\n",
    "        personality_instruction = \"You are a helpful AI assistant.\" # Fallback\n",
    "\n",
    "    sample[\"text\"] = f\"<s>[INST] {personality_instruction}\\n\\nQuestion: {question} [/INST]{answer}</s>\"\n",
    "    return sample\n",
    "\n",
    "def create_inference_prompt(personality_trait, question_with_choices):\n",
    "    \"\"\"Creates a conversational prompt for inference that matches the training style.\"\"\"\n",
    "    prompt = (\n",
    "        f\"<s>[INST] As an AI with a **{personality_trait}** personality, please answer the following question \"\n",
    "        f\"by explaining your reasoning.\\n\\n{question_with_choices} [/INST]\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def extract_question_and_choices(full_prompt_string):\n",
    "    \"\"\"Extract question and choices from OpinionQA prompt.\"\"\"\n",
    "    question_match = re.search(r'<question>(.*?)</question>', full_prompt_string, re.DOTALL)\n",
    "    choices_match = re.search(r'<choices>(.*?)</choices>', full_prompt_string, re.DOTALL)\n",
    "    question_text = question_match.group(1).strip() if question_match else \"\"\n",
    "    choices_raw_str = choices_match.group(1).strip() if choices_match else \"\"\n",
    "    return question_text, choices_raw_str\n",
    "\n",
    "def get_llm_response(model, tokenizer, personality_trait, question_with_choices, max_new_tokens=80, temperature=0.7):\n",
    "    \"\"\"Generates a response from the specified personality model.\"\"\"\n",
    "    prompt = create_inference_prompt(personality_trait, question_with_choices)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    if hasattr(model, 'set_adapter') and personality_trait != \"neutral\":\n",
    "        try:\n",
    "            adapter_name = personality_trait.lower().replace(\" \", \"_\")\n",
    "            model.set_adapter(adapter_name)\n",
    "        except Exception:\n",
    "            print(f\"Warning: Adapter for '{personality_trait}' not found. Using base model behavior.\")\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "        return response.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during model generation for '{personality_trait}': {e}\")\n",
    "        return \"ERROR: Generation failed\"\n",
    "\n",
    "# In the HELPER FUNCTIONS section\n",
    "\n",
    "def categorize_response_with_llm(judge_model, tokenizer, question, choices_str, response_to_judge):\n",
    "    \"\"\"\n",
    "    CORRECTED: Uses the base_model directly for judging, which is simpler and\n",
    "    avoids the `disable_adapters` error.\n",
    "    \"\"\"\n",
    "    judge_prompt = (\n",
    "        f\"<s>[INST] You are an impartial judge. Your task is to determine which choice a response supports. \"\n",
    "        f\"Analyze the 'Response to Judge' and determine which 'Choice' it most closely aligns with. \"\n",
    "        f\"You MUST respond with only the single capital letter of the corresponding choice (e.g., 'A', 'B'). Do not provide any explanation.\\n\\n\"\n",
    "        f\"**Question:** {question}\\n\"\n",
    "        f\"**Choices:** {choices_str}\\n\\n\"\n",
    "        f\"**Response to Judge:**\\n\\\"\\\"\\\"\\n{response_to_judge}\\n\\\"\\\"\\\"\\n\\n\"\n",
    "        f\"Which choice does the response support? Answer with a single capital letter only: [/INST]\"\n",
    "    )\n",
    "    inputs = tokenizer(judge_prompt, return_tensors=\"pt\").to(judge_model.device)\n",
    "\n",
    "    # NO MORE CONTEXT MANAGER NEEDED - we just use the judge_model directly\n",
    "    with torch.no_grad():\n",
    "        outputs = judge_model.generate(\n",
    "            **inputs, max_new_tokens=5, do_sample=False, pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    judge_response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
    "    match = re.search(r'([A-Z])', judge_response)\n",
    "    return match.group(1) if match else \"JUDGE_ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Setup ---\n",
      "Successfully logged into Hugging Face.\n",
      "\n",
      "--- PART 1: Loading Base Model and Tokenizer ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model and tokenizer loaded successfully.\n",
      "\n",
      "--- PART 2: Fine-Tuning Process ---\n",
      "All refined PEFT adapters found. Skipping fine-tuning.\n",
      "\n",
      "--- PART 3: Loading PEFT Models for Evaluation ---\n",
      "Loaded initial adapter: 'extraversion'\n",
      "Loaded additional adapter: 'agreeableness'\n",
      "Loaded additional adapter: 'neuroticism'\n",
      "Loaded additional adapter: 'openness'\n",
      "Loaded additional adapter: 'conscientiousness'\n",
      "\n",
      "Successfully loaded 5 adapters with explicit names.\n",
      "\n",
      "--- PART 4: Loading Personality Classifier ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PART 5: Running OpinionQA Evaluation ---\n",
      "  > Generating responses for: neutral\n",
      "  > Generating responses for: extraversion\n",
      "  > Generating responses for: agreeableness\n",
      "  > Generating responses for: neuroticism\n",
      "  > Generating responses for: openness\n",
      "  > Generating responses for: conscientiousness\n",
      "\n",
      "--- PART 6: Judging Responses and Analyzing Results ---\n",
      "  > Parsing responses with LLM-as-Judge...\n",
      "  > Classifying traits for alignment score...\n",
      "\n",
      "--- Opinion Accuracy (Parsed by LLM Judge) ---\n",
      "Overall Accuracy: 0.00%\n",
      "intended_personality\n",
      "agreeableness        0.00%\n",
      "conscientiousness    0.00%\n",
      "extraversion         0.00%\n",
      "neuroticism          0.00%\n",
      "neutral              0.00%\n",
      "openness             0.00%\n",
      "Name: is_opinion_correct, dtype: object\n",
      "\n",
      "--- Trait Alignment (Judged by External Classifier) ---\n",
      "Overall Trait Alignment: 65.00%\n",
      "intended_personality\n",
      "agreeableness        96.00%\n",
      "conscientiousness    51.00%\n",
      "extraversion         60.00%\n",
      "neuroticism          84.00%\n",
      "openness             34.00%\n",
      "Name: is_trait_correct, dtype: object\n",
      "\n",
      "Full results saved to 'final_refined_evaluation_results.csv'\n",
      "\n",
      "--- Experiment Complete ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# MAIN EXECUTION SCRIPT\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    # --- Setup ---\n",
    "    print(\"--- Initializing Setup ---\")\n",
    "    if HF_TOKEN:\n",
    "        login(token=HF_TOKEN)\n",
    "        print(\"Successfully logged into Hugging Face.\")\n",
    "    os.makedirs(OUTPUT_DIR_BASE, exist_ok=True)\n",
    "\n",
    "    # --- PART 1: Load Base Model & Tokenizer ---\n",
    "    print(\"\\n--- PART 1: Loading Base Model and Tokenizer ---\")\n",
    "    compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=use_4bit,\n",
    "        bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=use_nested_quant,\n",
    "    )\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=device_map,\n",
    "        torch_dtype=compute_dtype,\n",
    "        attn_implementation=\"sdpa\"\n",
    "    )\n",
    "    base_model.config.use_cache = False\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    tokenizer.model_max_length = max_seq_length\n",
    "    print(\"Base model and tokenizer loaded successfully.\")\n",
    "\n",
    "    # --- PART 2: Refined Fine-Tuning ---\n",
    "    print(\"\\n--- PART 2: Fine-Tuning Process ---\")\n",
    "    try:\n",
    "        df_personality_raw = load_dataset(PERSONALITY_DATASET_NAME, split='train').to_pandas()\n",
    "        target_personalities = df_personality_raw['Target Personality'].unique().tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL: Could not load personality dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    all_adapters_exist = all(\n",
    "        os.path.exists(os.path.join(OUTPUT_DIR_BASE, trait.lower().replace(\" \", \"_\")))\n",
    "        for trait in target_personalities\n",
    "    )\n",
    "\n",
    "    if all_adapters_exist:\n",
    "        print(\"All refined PEFT adapters found. Skipping fine-tuning.\")\n",
    "    else:\n",
    "        logging.set_verbosity_warning()\n",
    "        for current_trait in target_personalities:\n",
    "            print(f\"\\n***** REFINED FINE-TUNING FOR: {current_trait.upper()} *****\")\n",
    "            current_output_dir = os.path.join(OUTPUT_DIR_BASE, current_trait.lower().replace(\" \", \"_\"))\n",
    "            if os.path.exists(current_output_dir):\n",
    "                print(f\"Adapter for {current_trait} already exists. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            trait_df = df_personality_raw[df_personality_raw['Target Personality'] == current_trait]\n",
    "            train_dataset = Dataset.from_pandas(trait_df).map(enhanced_training_prompt_format)\n",
    "\n",
    "            peft_config = LoraConfig(lora_alpha=lora_alpha, lora_dropout=lora_dropout, r=lora_r, bias=\"none\", task_type=\"CAUSAL_LM\", target_modules=target_modules)\n",
    "            model = get_peft_model(base_model, peft_config)\n",
    "            \n",
    "            # *** MODIFIED: Reverted to the simpler SFTConfig to resolve the TypeError ***\n",
    "            training_args = SFTConfig(\n",
    "                output_dir=current_output_dir,\n",
    "                num_train_epochs=num_train_epochs,\n",
    "                per_device_train_batch_size=per_device_train_batch_size,\n",
    "                gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                optim=optim,\n",
    "                save_steps=save_steps,\n",
    "                logging_steps=logging_steps,\n",
    "                learning_rate=learning_rate,\n",
    "                weight_decay=weight_decay,\n",
    "                fp16=fp16,\n",
    "                bf16=bf16,\n",
    "                max_grad_norm=max_grad_norm,\n",
    "                max_steps=max_steps,\n",
    "                warmup_ratio=warmup_ratio,\n",
    "                group_by_length=group_by_length,\n",
    "                lr_scheduler_type=lr_scheduler_type,\n",
    "                report_to=\"tensorboard\",\n",
    "                max_seq_length=max_seq_length,\n",
    "                packing=packing,\n",
    "                dataset_text_field=\"text\",\n",
    "            )\n",
    "            # *** MODIFIED: The Trainer no longer takes an eval_dataset argument ***\n",
    "            trainer = SFTTrainer(\n",
    "                model=model,\n",
    "                train_dataset=train_dataset,\n",
    "                peft_config=peft_config,\n",
    "                args=training_args,\n",
    "            )\n",
    "            trainer.train()\n",
    "            trainer.save_model(current_output_dir)\n",
    "            del model, trainer\n",
    "            torch.cuda.empty_cache()    \n",
    "\n",
    "# --- PART 3: Load PEFT Models for Evaluation ---\n",
    "    print(\"\\n--- PART 3: Loading PEFT Models for Evaluation ---\")\n",
    "\n",
    "    # Get the name and path for the first adapter\n",
    "    first_trait = target_personalities[0]\n",
    "    first_adapter_name = first_trait.lower().replace(\" \", \"_\")\n",
    "    first_adapter_path = os.path.join(OUTPUT_DIR_BASE, first_adapter_name)\n",
    "\n",
    "    # *** THE FIX IS HERE: Explicitly name the first adapter when loading it. ***\n",
    "    # Instead of letting it be named \"default\", we assign its proper trait name.\n",
    "    peft_model = PeftModel.from_pretrained(\n",
    "        base_model,\n",
    "        first_adapter_path,\n",
    "        adapter_name=first_adapter_name,  # This ensures it's not named 'default'\n",
    "        is_trainable=False\n",
    "    )\n",
    "    print(f\"Loaded initial adapter: '{first_adapter_name}'\")\n",
    "\n",
    "\n",
    "    # Now, loop through the REST of the adapters and load them\n",
    "    for trait in target_personalities[1:]:\n",
    "        adapter_name = trait.lower().replace(\" \", \"_\")\n",
    "        adapter_path = os.path.join(OUTPUT_DIR_BASE, adapter_name)\n",
    "        peft_model.load_adapter(adapter_path, adapter_name=adapter_name)\n",
    "        print(f\"Loaded additional adapter: '{adapter_name}'\")\n",
    "\n",
    "    print(f\"\\nSuccessfully loaded {len(peft_model.peft_config)} adapters with explicit names.\")\n",
    "    # Now the get_llm_response function will correctly find every adapter by its trait name.\n",
    "\n",
    "    # --- PART 4: Load Personality Classifier ---\n",
    "    print(\"\\n--- PART 4: Loading Personality Classifier ---\")\n",
    "    try:\n",
    "        personality_classifier = pipeline(\"text-classification\", model=\"holistic-ai/personality_classifier\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load personality classifier: {e}\")\n",
    "        personality_classifier = None\n",
    "\n",
    "    # --- PART 5: OpinionQA Evaluation ---\n",
    "    print(\"\\n--- PART 5: Running OpinionQA Evaluation ---\")\n",
    "    try:\n",
    "        df_opinionqa = load_dataset(OPINIONQA_DATASET_NAME, split=\"test\").to_pandas()\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL: Could not load OpinionQA dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    all_results = []\n",
    "    all_eval_personalities = [\"neutral\"] + target_personalities\n",
    "    N_SAMPLES = 100\n",
    "    opinionqa_subset = df_opinionqa.sample(n=min(len(df_opinionqa), N_SAMPLES), random_state=42)\n",
    "\n",
    "    for personality_trait in all_eval_personalities:\n",
    "        print(f\"  > Generating responses for: {personality_trait}\")\n",
    "        for _, row in opinionqa_subset.iterrows():\n",
    "            question, choices_str = extract_question_and_choices(row['prompt'])\n",
    "            if not question or not choices_str: continue\n",
    "            \n",
    "            model_to_use = base_model if personality_trait == \"neutral\" else peft_model\n",
    "            response = get_llm_response(model_to_use, tokenizer, personality_trait, f\"Question: {question}\\nChoices: {choices_str}\")\n",
    "            all_results.append({\n",
    "                \"intended_personality\": personality_trait, \"question_id\": row['question_id'],\n",
    "                \"question\": question, \"choices_str\": choices_str,\n",
    "                \"human_answer_label\": row['answer'], \"llm_raw_response\": response,\n",
    "            })\n",
    "\n",
    "    # --- PART 6: Analysis of Results ---\n",
    "    print(\"\\n--- PART 6: Judging Responses and Analyzing Results ---\")\n",
    "    if not all_results:\n",
    "        print(\"FATAL ERROR: No evaluation results were generated.\")\n",
    "        return\n",
    "\n",
    "    df_results = pd.DataFrame(all_results)\n",
    "    print(\"  > Parsing responses with LLM-as-Judge...\")\n",
    "    df_results['llm_mapped_answer_label'] = df_results.apply(\n",
    "        lambda row: categorize_response_with_llm(base_model, tokenizer, row['question'], row['choices_str'], row['llm_raw_response']), axis=1\n",
    "    )\n",
    "    if personality_classifier:\n",
    "        print(\"  > Classifying traits for alignment score...\")\n",
    "        # Pass list for batching efficiency\n",
    "        classifier_output = personality_classifier(df_results['llm_raw_response'].tolist())\n",
    "        df_results['predicted_trait'] = [item['label'] for item in classifier_output]\n",
    "\n",
    "    parsed_df = df_results[df_results['llm_mapped_answer_label'] != 'JUDGE_ERROR'].copy()\n",
    "    if not parsed_df.empty:\n",
    "        parsed_df['is_opinion_correct'] = (parsed_df['llm_mapped_answer_label'] == parsed_df['human_answer_label'])\n",
    "        print(f\"\\n--- Opinion Accuracy (Parsed by LLM Judge) ---\")\n",
    "        print(f\"Overall Accuracy: {parsed_df['is_opinion_correct'].mean():.2%}\")\n",
    "        print(parsed_df.groupby('intended_personality')['is_opinion_correct'].mean().map(\"{:.2%}\".format))\n",
    "\n",
    "    if personality_classifier and 'predicted_trait' in df_results.columns:\n",
    "        df_ta = df_results[df_results['intended_personality'] != 'neutral'].copy()\n",
    "        if not df_ta.empty:\n",
    "            df_ta['is_trait_correct'] = (df_ta['intended_personality'] == df_ta['predicted_trait'])\n",
    "            print(f\"\\n--- Trait Alignment (Judged by External Classifier) ---\")\n",
    "            print(f\"Overall Trait Alignment: {df_ta['is_trait_correct'].mean():.2%}\")\n",
    "            print(df_ta.groupby('intended_personality')['is_trait_correct'].mean().map(\"{:.2%}\".format))\n",
    "\n",
    "    results_filename = \"final_refined_evaluation_results.csv\"\n",
    "    df_results.to_csv(results_filename, index=False)\n",
    "    print(f\"\\nFull results saved to '{results_filename}'\")\n",
    "    print(\"\\n--- Experiment Complete ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
